
- 一般而言，“**朴素感知机**”是指**单层网络**，指的是激活函数使用了阶跃函数 的模型。“多层感知机”是指神经网络，即使用 sigmoid 函数等平滑的激活函数的多层网络。

- sigmoid函数的平滑性对神经网络的学习

- 使用线性函数的话，加深神经网络的层数就没有意义了。


1. 神经网络存在合适的权重和偏置，调整权重和偏置以便拟合训练数据的 过程称为“学习”。神经网络的学习分成下面4个步骤。

 - 步骤1（mini-batch） 从训练数据中随机选出一部分数据，这部分数据称为mini-batch。我们 的目标是减小mini-batch的损失函数的值。 
 - 步骤2（计算梯度） 为了减小mini-batch的损失函数的值，需要求出各个权重参数的梯度。 梯度表示损失函数的值减小最多的方向。 
 - 步骤3（更新参数） 将权重参数沿梯度方向进行微小更新。、
 - 步骤4（重复） 重复步骤1、步骤2、步骤3。


2.  🧠 举个通俗的例子来理解：

	假设有60000张图片（训练样本），想训练10轮（epoch），每次拿100张训练：

| 名称             | 数值                       | 含义                           |
| -------------- | ------------------------ | ---------------------------- |
| batch_size     | 100                      | 每次训练看100张图片                  |
| iter_per_epoch | 600                      | 每训练600次就算一轮                  |
| iters_num      | 10000                    | 总共训练10000次，也就是 10000 个 batch |
| 总共训练轮数（epoch数） | 10000 / 600 = 16.66 ≈ 17 | 大概训练了 17 个 epoch             |
