## **1. 语料库维度：**
- 语言
- 司法管辖区
- 查询总数
- 每个查询的平均候选案例数
- 每个查询的平均相关案例数
## **2. 数据集**
#### **2.1.普通法法域数据集**
- 相似性判断通常通过引用关系自动得出：一个案例**引用另一个即视为相似**。
- **COLIEE 2021–2023**：案例来自加拿大联邦法院，查询案例和先例都作为候选池提供。
- **FIRE-IRLeD 2017**：案件来自印度最高法院，仅提供先例及1000个随机非查询案件作为候选；负例为手动选定。with cases other than the precedents serving as negative ones。
#### **2.2 民法法域数据集**
- **LeCaRD3 和 CAIL2019-SCM**：均由法律专家标注相似性。
- **LeCaRD**：使用IR模型（即TF-IDF、  BM25和语言建模)）选出100个候选案例，人工判断相似性；所有标注员都接受统一 的标注指南培训,实现了Fleiss的kappa系数0.5 的协议。
- **CAIL2019-SCM**：首先利用TF-IDF从  案例库中为每个查询收集两个候选案例，判断哪一个更相似。标注训练和**一致性未明**。

下文简记为：**CO/FI/Le/CA**
### **3 数据集限制**

#### **3.1 注释偏差**
- 普通法数据集使用引文标注，但引用理由常非事实相似。
- 法官引用可能受政治偏好或个人偏见影响（例如引用同政党法官案例）。
- 偏见标注训练出的模型可能产生不公预测，构成伦理问题。
#### **3.2 可重复性问题**
如LeCaRD、CAIL2019-SCM
- 民法数据集未公开标注指南或一致性报告。
- 不符合当前NLP社区对数据集可重复性的标准。

#### **3.3 时间意识不足**（挑战4）
- 当前数据集未考虑时间维度。
- 理想数据集应包含不同时间点的案例，反映法律和法规随时间变化对相似性判断的影响。 

#### **4. 缺乏通俗易懂的解释数据集**

- 现有少数LCR数据集附带解释，但大多难以为外行理解。
- 图2展示两种解释方式：
    - 法律专家撰写的简要解释，外行难以理解。
    - 理想解释：明确指出案件相似性判断的逻辑步骤，并提供法律支持依据。
**示例分析**：
- **Case 1**：Qxx借款500万，利率21%，逾期未还。
- **Case 2**：Gxx借款300万，利率7%，逾期未还。
- **已有解释**：两个案件均未按期履约，但Case 1利率高于市场利率四倍；Case 2则合法。
- **理想解释**：尽管两案均为违约，但依据《民间借贷法》第25条，Case 1利率过高，不受保护，Case 2则在保护范围内；因此两者不相似。
#### **5. 不恰当的使用**
- 一些研究者在模型训练中使用了查询案例的全部信息（包括法院裁判和推理）。
- 实际应用中，模型应在最终裁决前使用，仅基于案件事实进行判断。