## **1. ASA 中的 [[评价指标]]**

## 🎯 假设场景
你设计了一个法律案件检索系统，输入一个案件（查询案例），系统输出最相似的5个历史案件。
我们有一个真实的人工标注数据：
- 这个查询案例的真实“相似案件”有：**A, B, C**
你系统的检索结果是：
- 系统返回了：**A, D, E, F, B**（共5个）
---
## 📌 1. Accuracy@K （命中率）
**定义**：前K个结果中，有没有**至少一个**是真实的相似案件？
- 如果K=5：
    - 系统返回了 A 和 B，都是正确答案 → 有命中 → Accuracy@5 = **1**
- 如果K=1：
    - 系统只返回了 A → 仍然命中 → Accuracy@1 = **1**
- 如果K=1，系统返回了 D → 没命中 → Accuracy@1 = **0**
**用途**：只关注有没有命中，不在意顺序或有几个。

---
## 📌 2. Precision@K（精准率）
**定义**：前K个返回结果中，有多少比例是真正的相似案件？
- K=5，系统返回了 A, D, E, F, B → 正确的有 A 和 B
- 所以 Precision@5 = 2 / 5 = **0.4**
**用途**：反映系统返回的前K个结果中，有多少是“靠谱”的。

---
## 📌 3. Recall@K（召回率）
**定义**：系统找回了多少比例的真实相似案件？
- 真实的相似案件是 A, B, C（共3个）
- 系统找回了 A 和 B → Recall@5 = 2 / 3 = **0.666**
**用途**：衡量系统有没有“尽可能多”找回所有相关案件。

---
## 📌 4. F1@K（调和平均）
**定义**：综合考虑 Precision 和 Recall 的指标。
公式：
F1@K=2×P@K×R@KP@K+R@KF1@K = \frac{2 \times P@K \times R@K}{P@K + R@K}
F1@K=P@K+R@K2×P@K×R@K
用刚才的值：
- P@5 = 0.4，R@5 = 0.666
F1@5=2×0.4×0.6660.4+0.666≈0.5F1@5 = \frac{2 \times 0.4 \times 0.666}{0.4 + 0.666} \approx 0.5
F1@5=0.4+0.6662×0.4×0.666≈0.5

---

## 📌 5. NDCG@K（折扣化累计增益）

**定义**：考虑“命中结果的排序”的指标，排名越靠前，得分越高。
公式有点复杂，但思想是：
- 如果你把 A 排在第1名，B第2名，系统得分高；
- 如果把 C 排在第5名，系统得分低（因为用户更可能只看前几条）。
NDCG 介于 0~1 之间，越高说明排序越合理。

---

## 📌 6. MAP（平均准确率）

**定义**：平均每个真实相似案件被检索出来时的“命中位置”的平均值。
例子中：
- A 在第1名被命中，精度是$1/1 = 1.0$
- B 在第5名被命中，精度是$2/5 = 0.4$
- C 没有命中 → 忽略
$MAP=(1.0+0.4)/2=0.7$

**用途**：越高说明系统越善于把真正相关案件排在前面。